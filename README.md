# Databricks 14-Days AI Challenge – 2

This repository documents my work and progress during the **Databricks 14-Days AI Challenge – Advanced Edition**.

Throughout this challenge, I will be uploading daily tasks, notebooks, implementations, and learnings. The focus is on building practical, production-style solutions using Databricks, Spark, Delta Lake, and ML tools.

---

## What This Challenge Covers

By completing this challenge, I am developing:

- Strong understanding of intermediate Databricks workflows  
- Ability to optimize Delta tables and improve performance  
- Experience building production-style feature tables  
- Hands-on ML model training, tuning, and tracking with MLflow  
- Ability to build recommendation systems  
- Understanding of job scheduling and basic streaming  
- Confidence designing an end-to-end AI + data pipeline  

---

## Repository Structure

The repository will be updated daily and organized as follows:

```
day1/
day2/
day3/
...
day14/
```

Each folder may contain:

- Databricks notebooks (.ipynb)
- ML experiments
- Feature engineering workflows
- Model training and MLflow tracking code
- Supporting documentation or notes

---

## Core Technologies Used

- Databricks
- Apache Spark
- PySpark
- Delta Lake
- MLflow
- SQL
- Streaming (Structured Streaming)
- Lakehouse Architecture

---

## Objective

The goal of this challenge is to gain practical experience in building scalable, optimized, and production-ready data + AI systems using the Databricks platform.

This repository serves as:

- A structured learning log
- A hands-on project portfolio

---

## Progress

Daily updates will be pushed as tasks are completed.

Stay tuned for continuous improvements and implementations.
