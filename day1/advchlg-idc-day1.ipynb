{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17f79c3d-7c46-4fa9-8c53-d5bee273f534",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fix schema mismatch for Delta table"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Optimization:\n\nNumber of Files:  51\n\nTotal File Size:  1493565463\n\n\nAfter Optimization:\n\nNumber of Files:  41\n\nTotal File Size:  1499012468\n"
     ]
    }
   ],
   "source": [
    "# Load data into spark dataFrame\n",
    "october_df = spark.read.option(\"header\", True).csv(\"/Volumes/workspace/advecom/advecom_data/2019-Oct.csv\")\n",
    "\n",
    "# Drop table to avoid incorrect previous schemas issues\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS oct_events_delta_new\"\"\")\n",
    "\n",
    "# Write dataFrame as new delta table\n",
    "october_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"oct_events_delta_new\")\n",
    "\n",
    "# Simulate small file problem by appending multiple times\n",
    "for _ in range(8):\n",
    "    october_df.limit(400).write.format(\"delta\").mode(\"append\").saveAsTable(\"oct_events_delta_new\")\n",
    "\n",
    "# Check number and size of files before optimization\n",
    "tableinfo_before = spark.sql(\"\"\"DESCRIBE DETAIL oct_events_delta_new\"\"\").collect()[0]\n",
    "print(\"Before Optimization:\")\n",
    "print(\"\\nNumber of Files: \",tableinfo_before['numFiles'])\n",
    "print(\"\\nTotal File Size: \",tableinfo_before['sizeInBytes'])\n",
    "\n",
    "# Optimize table\n",
    "spark.sql(\"\"\"OPTIMIZE oct_events_delta_new\"\"\")\n",
    "\n",
    "# Check number and size of files after optimization\n",
    "tableinfo_after = spark.sql(\"\"\"DESCRIBE DETAIL oct_events_delta_new\"\"\").collect()[0]\n",
    "print(\"\\n\\nAfter Optimization:\")\n",
    "print(\"\\nNumber of Files: \",tableinfo_after['numFiles'])\n",
    "print(\"\\nTotal File Size: \",tableinfo_after['sizeInBytes'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ac3fe4b-bf53-427e-9535-534fd403ef8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation from the simulation of small files problem\nDifference in Number of Files 10\nDifference in File Size -5447005\n"
     ]
    }
   ],
   "source": [
    "# Observation from the simulation\n",
    "print(\"Observation from the simulation of small files problem\")\n",
    "print(\"Difference in Number of Files\", tableinfo_before['numFiles'] - tableinfo_after['numFiles'])\n",
    "print(\"Difference in File Size\", tableinfo_before['sizeInBytes'] - tableinfo_after['sizeInBytes'])"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "advchlg-idc-day1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}